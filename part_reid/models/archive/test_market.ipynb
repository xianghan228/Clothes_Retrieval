{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#init net\n",
    "DATA_DIR= '../../dataset/market/Market-1501/'\n",
    "MODEL_FILE = 'test.prototxt'\n",
    "PRETRAINED = 'model_market.caffemodel'\n",
    "model_name=PRETRAINED[PRETRAINED.rfind('/')+1:-11]\n",
    "\n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE, PRETRAINED,caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N,C,H,W=net.blobs['data'].data.shape\n",
    "crop_h=crop_w=0\n",
    "transformer = caffe.io.Transformer({'data': (N,C,H+2*crop_h,W+2*crop_w)})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data', np.array([ 104,  117,  123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "\n",
    "def readImages(images):\n",
    "    imageLen=len(images)\n",
    "    imageDataList=[]\n",
    "    for imageIdx in range(imageLen):\n",
    "        imageName=images[imageIdx]\n",
    "        imageImage=transformer.preprocess('data', caffe.io.load_image(imageName))\n",
    "        imageDataList.append(imageImage[:,crop_h:H+crop_h,crop_w:W+crop_w]) #center crop\n",
    "        imageIdx+=1\n",
    "    #imageData and imageData\n",
    "    imageData=np.asarray(imageDataList)\n",
    "    return imageData\n",
    "\n",
    "def readDir(list_dir):\n",
    "    import os\n",
    "    file_list=os.listdir(list_dir)\n",
    "    final_list=[]\n",
    "    for filename in file_list:\n",
    "        if filename[0]!='-' and filename[filename.rfind('.')+1:]=='jpg':\n",
    "            final_list.append(list_dir+filename)\n",
    "    return final_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(file_list):\n",
    "    file_len=len(file_list)\n",
    "    features=[]\n",
    "    batch_size=200\n",
    "    for batch_idx in range(file_len/batch_size+1):\n",
    "        cur_len=batch_size if batch_idx <file_len/batch_size else file_len%batch_size\n",
    "        cur_list=file_list[batch_idx*batch_size+0:batch_idx*batch_size+cur_len]\n",
    "        image_data=readImages(cur_list)\n",
    "        net.blobs['data'].reshape(cur_len,C,H,W)\n",
    "        net.blobs['data'].data[:] = image_data\n",
    "        net.forward()\n",
    "        normed_features=net.blobs['concat_features'].data.copy()\n",
    "        from sklearn.preprocessing import normalize\n",
    "        for idx in range(cur_len):\n",
    "            cur_feature=np.squeeze(normed_features[idx,:])\n",
    "            cur_feature = cur_feature/np.linalg.norm(cur_feature)\n",
    "            features.append(cur_feature)\n",
    "    return features\n",
    "def get_gt_dict(gallery_list):\n",
    "    gt_dict={}\n",
    "    for idx in range(len(gallery_list)):\n",
    "        gallery_name=gallery_list[idx]\n",
    "        gallery_person_id=gallery_name[gallery_name.rfind('/')+1:gallery_name.rfind('/')+5]\n",
    "        gallery_cam_id=gallery_name[gallery_name.rfind('/')+7:gallery_name.rfind('/')+8]\n",
    "        if gt_dict.has_key(gallery_person_id):\n",
    "            gt_dict[gallery_person_id].append(idx)\n",
    "        else:\n",
    "            gt_dict[gallery_person_id]=[idx]\n",
    "    return gt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3368 15913 751 2798\n"
     ]
    }
   ],
   "source": [
    "query_list=readDir(DATA_DIR+'query/')\n",
    "gallery_list=readDir(DATA_DIR+'bounding_box_test/')\n",
    "gt_dict=get_gt_dict(gallery_list)\n",
    "print len(query_list),len(gallery_list),len(gt_dict),len(gt_dict['0000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "tic=time.time()\n",
    "query_features=extract_features(query_list)\n",
    "gallery_features=extract_features(gallery_list)\n",
    "toc=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.6539011002 0.00314578606401\n"
     ]
    }
   ],
   "source": [
    "print (toc-tic),(toc-tic)/(len(query_list)+len(gallery_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_for_queries(query_features,gallery_features):\n",
    "    import numpy as np\n",
    "    all_rank_list=[]\n",
    "    for query_idx in range(len(query_features)):\n",
    "        query_feature=query_features[query_idx]\n",
    "\n",
    "        score_list=[]\n",
    "        for gallery_idx in range(len(gallery_features)):\n",
    "            gallery_feature=gallery_features[gallery_idx]\n",
    "            dist = np.sqrt(np.sum((query_feature-gallery_feature)**2))\n",
    "            similar_score=1.0/(1.0+dist)\n",
    "            score_list.append(similar_score)\n",
    "        #we get scoreList, then cal predictLists\n",
    "        ranked_idx_list=np.argsort(score_list)[::-1]\n",
    "        all_rank_list.append(ranked_idx_list)\n",
    "    return all_rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_rank_list=rank_for_queries(query_features,gallery_features)\n",
    "\n",
    "######################################################\n",
    "##\n",
    "## I use parallel to run the query in batch_num=10 batches\n",
    "## In this way, one query on the 1w galleries takes 0.027s\n",
    "## Multi-process does not work for ipython notebook on Windows\n",
    "##\n",
    "######################################################\n",
    "\n",
    "# import ipyparallel as ipp\n",
    "# client = ipp.Client()\n",
    "# view = client.load_balanced_view()\n",
    "# batch_num=2*len(client.ids)\n",
    "# print batch_num\n",
    "# batch_size_queries=len(query_features)/batch_num+1\n",
    "\n",
    "# tic=time.time()\n",
    "# task_results=[]\n",
    "# for task_idx in range(batch_num):\n",
    "#     batch_query_features=query_features[task_idx*batch_size_queries:(task_idx+1)*batch_size_queries]\n",
    "#     task_results.append(view.apply(rank_for_queries,batch_query_features,gallery_features))    \n",
    "    \n",
    "# all_rank_list=[]\n",
    "# for task_idx in range(batch_num):\n",
    "#     all_rank_list.extend(task_results[task_idx].result())\n",
    "# toc=time.time()\n",
    "# print len(all_rank_list),(toc-tic),(toc-tic)/len(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80967933  0.86846793  0.89608076  0.91003563  0.91983373  0.92814727\n",
      "  0.93408551  0.93853919  0.94388361  0.94714964  0.95071259  0.95368171\n",
      "  0.95635392  0.95872922  0.9608076   0.96229216  0.96437055  0.96644893\n",
      "  0.96704276  0.96733967  0.9682304   0.97001188  0.97179335  0.97238717\n",
      "  0.97327791  0.97357482  0.97387173  0.97416865  0.97416865  0.97476247\n",
      "  0.97505938  0.97565321  0.97624703  0.97684086  0.97713777  0.97773159\n",
      "  0.97832542  0.97862233  0.97862233  0.97980998  0.97980998  0.9804038\n",
      "  0.98070071  0.98070071  0.98099762  0.98159145  0.98188836  0.98188836\n",
      "  0.98218527  0.98218527] 0.634278192554\n"
     ]
    }
   ],
   "source": [
    "histogram=np.zeros(len(gallery_list))\n",
    "meanAP=0.0\n",
    "len_queries=len(query_list)\n",
    "for query_idx in range(len_queries):#\n",
    "    ranked_idx_list=all_rank_list[query_idx]\n",
    "    #good or junk\n",
    "    query_name=query_list[query_idx]\n",
    "    query_person_id=query_name[query_name.rfind('/')+1:query_name.rfind('/')+5]\n",
    "    query_cam_id=query_name[query_name.rfind('/')+7:query_name.rfind('/')+8]\n",
    "    relevant_idx_list=gt_dict[query_person_id]\n",
    "    good_relevant=[]\n",
    "    junk_relevant=[]\n",
    "    for relevant_idx in relevant_idx_list:\n",
    "        gallery_name=gallery_list[relevant_idx]\n",
    "        gallery_cam_id=gallery_name[gallery_name.rfind('/')+7:gallery_name.rfind('/')+8]\n",
    "        if gallery_cam_id==query_cam_id:\n",
    "            junk_relevant.append(relevant_idx)\n",
    "        else:\n",
    "            good_relevant.append(relevant_idx)\n",
    "    #cmc and meanAP\n",
    "    matched_num=0.0\n",
    "    sum_precision=0.0\n",
    "    rank_idx=0\n",
    "    for perdicted_idx in ranked_idx_list:\n",
    "        if perdicted_idx in junk_relevant:\n",
    "            continue\n",
    "        elif perdicted_idx in good_relevant:\n",
    "            matched_num+=1.0\n",
    "            sum_precision+=matched_num/(rank_idx+1)\n",
    "            histogram[rank_idx]+= 1 if matched_num<=1 else 0 #multiple results\n",
    "        rank_idx+=1\n",
    "        if matched_num>=len(good_relevant): #recall=1\n",
    "            break\n",
    "    meanAP+=sum_precision/len(good_relevant)\n",
    "        \n",
    "cmc=np.cumsum(histogram)/len_queries\n",
    "meanAP/=len_queries\n",
    "print cmc[:50],meanAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_market,160x80,crop=0: 0.809679334917 0.634278192554\n"
     ]
    }
   ],
   "source": [
    "print model_name+\",\"+\"%dx%d,crop=%d\"%(H,W,crop_h)+\":\",cmc[0],meanAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
