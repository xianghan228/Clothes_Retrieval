{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#init net\n",
    "DATASET_DIR='../../dataset/cuhk01/campus/'\n",
    "EXP_NAME='./py486/'\n",
    "MODEL_FILE = EXP_NAME+'test.prototxt'\n",
    "PRETRAINED = EXP_NAME+'snapshot/model_iter_40000.caffemodel'\n",
    "ROOT='/home/liming/cluster/project/reid/train/cuhk01/'\n",
    "EXP_NAME=ROOT+'orig_aug'\n",
    "MODEL_FILE = EXP_NAME+'/test.prototxt'\n",
    "PRETRAINED = EXP_NAME+'/snapshot/cuhk01_iter_48000.caffemodel' \n",
    "\n",
    "#'snapshot/model_iter_1000.caffemodel'\n",
    "# PRETRAINED = '../../dataset/cuhk01/models/cuhk01_486_iter_100000.caffemodel'\n",
    "model_name = EXP_NAME+PRETRAINED[PRETRAINED.rfind('_'):-11]\n",
    "TEST_NUM=486\n",
    "# TEST_NUM=100\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE, PRETRAINED,caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateCMC(gtLabels,predictLists):\n",
    "    N=len(gtLabels)\n",
    "    R=len(predictLists[0])\n",
    "    histogram=np.zeros(N)\n",
    "    for testIdx in range(N):\n",
    "        for rankIdx in range(R):\n",
    "            histogram[rankIdx]+=1*(predictLists[testIdx][rankIdx]==gtLabels[testIdx])    #1*(true or false)=1 or 0\n",
    "    cmc=np.cumsum(histogram)\n",
    "    return cmc/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N,C,H,W=net.blobs['data'].data.shape\n",
    "h=0;w=0 #padding\n",
    "transformer = caffe.io.Transformer({'data': (N,C,H+h*2,W+w*2)})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data', np.array([ 104,  117,  123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "def readImages(images):\n",
    "    imageLen=len(images)\n",
    "    imageDataList=[]\n",
    "    for imageIdx in range(imageLen):\n",
    "        imageName=images[imageIdx]\n",
    "        imageImage=transformer.preprocess('data', caffe.io.load_image(imageName))\n",
    "        imageDataList.append(imageImage[:,h:h+H,w:w+W]) \n",
    "        imageIdx+=1\n",
    "    #imageData and imageData\n",
    "    imageData=np.asarray(imageDataList)\n",
    "    return imageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readDir(DATA_DIR):\n",
    "    test_num=TEST_NUM\n",
    "    all_id={}\n",
    "    file_lists=glob.glob(DATA_DIR+'*.png')\n",
    "    for filename in file_lists:\n",
    "        idx=filename.rfind('/')\n",
    "        image_name=filename[idx+1:]\n",
    "        person_id_str=image_name[:4]\n",
    "        person_id = int(person_id_str)\n",
    "        if all_id.has_key(person_id):\n",
    "            all_id[person_id].append(filename)\n",
    "        else:\n",
    "            all_id[person_id]=[filename]\n",
    "\n",
    "    id_names=all_id.keys()\n",
    "    np.random.seed(0)\n",
    "    train_idx_list=np.random.choice(id_names,len(id_names)-test_num,replace=False)\n",
    "\n",
    "    test_idx_list=[]\n",
    "    for x in id_names:\n",
    "        if x not in train_idx_list:\n",
    "            test_idx_list.append(x)\n",
    "    print test_idx_list[:10]\n",
    "    return test_idx_list, all_id\n",
    "\n",
    "def readList(test_idx_list,all_id,DATA_DIR,rand_seed=0): \n",
    "    #print all_the_text\n",
    "    probes=[]\n",
    "    gallerys=[]\n",
    "    #make sure random keeps seems for all experiments\n",
    "    random.seed(rand_seed+10)\n",
    "    for person_id in test_idx_list:\n",
    "        probe_file_name=DATA_DIR+\"%04d%03d.png\"%(person_id,random.randint(1,2))\n",
    "        gallery_file_name=DATA_DIR+\"%04d%03d.png\"%(person_id,random.randint(3,4))\n",
    "        probes.append(probe_file_name)\n",
    "        gallerys.append(gallery_file_name)\n",
    "    return probes,gallerys\n",
    "\n",
    "def calCMC(net,rand_times=10,DATA_DIR= '../../dataset/cuhk01/campus/'):\n",
    "    cmc_list=[]\n",
    "    rand_seeds=range(1,rand_times+1)\n",
    "    test_idx_list, all_id=readDir(DATA_DIR)\n",
    "    for i in range(rand_times):\n",
    "        print 'Round %d with rand list:'%i\n",
    "        probes,gallerys=readList(test_idx_list,all_id,DATA_DIR,rand_seeds[i])\n",
    "        predictLists=generateScoreList(net,probes,gallerys)\n",
    "        gtLabels=range(len(probes))\n",
    "        cmc=evaluateCMC(gtLabels,predictLists)\n",
    "        cmc_list.append(cmc)\n",
    "        print cmc[0:5]\n",
    "    return np.average(cmc_list,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateScoreList(net,probes,gallerys):\n",
    "    N,C,H,W=net.blobs['data'].data.shape\n",
    "    from time import clock\n",
    "    start=clock()\n",
    "    #galleryData is same for each probe\n",
    "    query_features=extract_features(probes)\n",
    "    gallery_features=extract_features(gallerys)\n",
    "    feature_time=clock()\n",
    "    all_rank_list=rank_for_queries(query_features,gallery_features)\n",
    "    rank_time=clock()\n",
    "    print \"feature_time:\",(feature_time-start),\"; rank_time:\",(rank_time-start)\n",
    "    return all_rank_list\n",
    "\n",
    "\n",
    "def extract_features(file_list):\n",
    "    file_len=len(file_list)\n",
    "    features=[]\n",
    "    batch_size=100\n",
    "    round_times=file_len/batch_size+(1 if file_len%batch_size else 0)\n",
    "    for batch_idx in range(round_times):\n",
    "        cur_len=batch_size if batch_idx <file_len/batch_size else file_len%batch_size\n",
    "        cur_list=file_list[batch_idx*batch_size+0:batch_idx*batch_size+cur_len]\n",
    "        image_data=readImages(cur_list)\n",
    "        net.blobs['data'].reshape(cur_len,C,H,W)\n",
    "        net.blobs['data'].data[:] = image_data\n",
    "        net.forward()\n",
    "        normed_features=net.blobs['normed_feature'].data.copy()\n",
    "        for idx in range(cur_len):\n",
    "            cur_feature=np.squeeze(normed_features[idx,:])\n",
    "            features.append(cur_feature)\n",
    "    return features\n",
    "\n",
    "\n",
    "def rank_for_queries(query_features,gallery_features):\n",
    "    import numpy as np\n",
    "    all_rank_list=[]\n",
    "    for query_idx in range(len(query_features)):\n",
    "        query_feature=query_features[query_idx]\n",
    "\n",
    "        score_list=[]\n",
    "        for gallery_idx in range(len(gallery_features)):\n",
    "            gallery_feature=gallery_features[gallery_idx]\n",
    "            dist = np.sqrt(np.sum((query_feature-gallery_feature)**2))\n",
    "            similar_score=1.0/(1.0+dist)\n",
    "            score_list.append(similar_score)\n",
    "        #we get scoreList, then cal predictLists\n",
    "        ranked_idx_list=np.argsort(score_list)[::-1]\n",
    "        all_rank_list.append(ranked_idx_list)\n",
    "    return all_rank_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 5, 8, 10, 12, 14, 17, 20, 24]\n",
      "Round 0 with rand list:\n",
      "feature_time: 3.103496 ; rank_time: 4.806782\n",
      "[ 0.75720165  0.83127572  0.87860082  0.90123457  0.91152263]\n",
      "Round 1 with rand list:\n",
      "feature_time: 3.065403 ; rank_time: 4.778409\n",
      "[ 0.74279835  0.82921811  0.85802469  0.88888889  0.90534979]\n",
      "Round 2 with rand list:\n",
      "feature_time: 3.057173 ; rank_time: 4.757918\n",
      "[ 0.75720165  0.83127572  0.88683128  0.90740741  0.91975309]\n",
      "Round 3 with rand list:\n",
      "feature_time: 3.061629 ; rank_time: 4.785681\n",
      "[ 0.74897119  0.82304527  0.85802469  0.88888889  0.90534979]\n",
      "Round 4 with rand list:\n",
      "feature_time: 3.060967 ; rank_time: 4.767766\n",
      "[ 0.72633745  0.81893004  0.86213992  0.88683128  0.90740741]\n",
      "Round 5 with rand list:\n",
      "feature_time: 3.063925 ; rank_time: 4.772312\n",
      "[ 0.72633745  0.81687243  0.84773663  0.8744856   0.88683128]\n",
      "Round 6 with rand list:\n",
      "feature_time: 3.062059 ; rank_time: 4.76514\n",
      "[ 0.73045267  0.7962963   0.8600823   0.89506173  0.91152263]\n",
      "Round 7 with rand list:\n",
      "feature_time: 3.061169 ; rank_time: 4.777014\n",
      "[ 0.7345679   0.81893004  0.85802469  0.87860082  0.89300412]\n",
      "Round 8 with rand list:\n",
      "feature_time: 3.060392 ; rank_time: 4.761381\n",
      "[ 0.74485597  0.81481481  0.85185185  0.87654321  0.90329218]\n",
      "Round 9 with rand list:\n",
      "feature_time: 3.063555 ; rank_time: 4.777745\n",
      "[ 0.72839506  0.81481481  0.85802469  0.88683128  0.90329218]\n",
      "Round 10 with rand list:\n",
      "feature_time: 3.062063 ; rank_time: 4.767646\n",
      "[ 0.75102881  0.83127572  0.87860082  0.89711934  0.91358025]\n",
      "Round 11 with rand list:\n",
      "feature_time: 3.067015 ; rank_time: 4.78251\n",
      "[ 0.72633745  0.82716049  0.86831276  0.89917695  0.91769547]\n",
      "Round 12 with rand list:\n",
      "feature_time: 3.060366 ; rank_time: 4.767043\n",
      "[ 0.74074074  0.81687243  0.86625514  0.88271605  0.8909465 ]\n",
      "Round 13 with rand list:\n",
      "feature_time: 3.064437 ; rank_time: 4.788301\n",
      "[ 0.718107    0.7962963   0.84567901  0.87654321  0.90123457]\n"
     ]
    }
   ],
   "source": [
    "#caculate CMC\n",
    "cmc_list=[]\n",
    "cmc=calCMC(net,rand_times=14)\n",
    "cmc_list.append(cmc)\n",
    "cmc_all=np.average(cmc_list,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuhk01 test486\n",
      "/home/liming/cluster/project/reid/train/cuhk01/orig_aug_48000; (H,W)=160,80\n",
      "\n",
      "CMC from rank 1 to rank 486:\n",
      "[ 0.73809524  0.81907701  0.86272781  0.88859494  0.90505585  0.91534392\n",
      "  0.92489712  0.93268665  0.93885949  0.94312169  0.94664903  0.95047031\n",
      "  0.95385068  0.95737801  0.9595826   0.96266902  0.96546149  0.96707819\n",
      "  0.9691358   0.97045855  0.97281011  0.97413286  0.97545561  0.97663139\n",
      "  0.97721928  0.97824809  0.97898295  0.9792769   0.97957084  0.98001176\n",
      "  0.98045267  0.98089359  0.98206937  0.98236332  0.98295121  0.98309818\n",
      "  0.98353909  0.98398001  0.9845679   0.98471487  0.98486185  0.98515579\n",
      "  0.98544974  0.98574368  0.98647854  0.98647854  0.98662551  0.98691946\n",
      "  0.98736038  0.98765432]\n",
      "73.8\t90.5\t94.3\t97.0\n"
     ]
    }
   ],
   "source": [
    "print 'cuhk01 test'+str(TEST_NUM)\n",
    "print model_name+'; (H,W)='+str(H)+','+str(W)+'\\n'\n",
    "print('CMC from rank 1 to rank %d:'%(len(cmc_all)))\n",
    "print(cmc_all[:50])\n",
    "print('%.1f\\t%.1f\\t%.1f\\t%.1f'%(100*cmc[0],100*cmc[4],100*cmc[9],100*cmc[19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-2fadc561b29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fds' is not defined"
     ]
    }
   ],
   "source": [
    "fds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "class test():\n",
    "    def __init__(self):\n",
    "        self.all_id=[0,1,2,3,4,5]\n",
    "        self.index=0\n",
    "        self.batch_size=3\n",
    "        self.id_dict={}\n",
    "        for id in self.all_id:\n",
    "            self.id_dict[id]=['id:%d'%(100*id)]*2\n",
    "            \n",
    "    def get_batch_list(self):\n",
    "        count=0\n",
    "        cur_range=xrange(self.index,self.index+self.batch_size)\n",
    "        for idx in cur_range:\n",
    "            if idx>=len(self.all_id):\n",
    "                random.shuffle(self.all_id)\n",
    "            self.index=idx%len(self.all_id)\n",
    "            id=self.all_id[self.index]\n",
    "            for file_name in self.id_dict[id][:self.max_per_id]:\n",
    "                if count < self.batch_size:\n",
    "                    count = count+1\n",
    "                    yield (file_name,id)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def info(self):\n",
    "        batch_list=self.get_batch_list()\n",
    "        for a,b in batch_list:\n",
    "            print a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
