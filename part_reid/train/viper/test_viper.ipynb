{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#init net\n",
    "EXP_DIR='./viper_origin_with_cuhk/'\n",
    "MODEL_FILE = EXP_DIR+'test.prototxt'\n",
    "PRETRAINED = EXP_DIR+'snapshot/model_iter_8000.caffemodel'#market_512_sigmoid_iter_26843.caffemodel'\n",
    "# PRETRAINED = '../cuhk03/base_networks/googlenet/snapshot/model_iter_20000.caffemodel'\n",
    "model_name=PRETRAINED[PRETRAINED.rfind('/')+1:-11]\n",
    "\n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE, PRETRAINED,caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N,C,H,W=net.blobs['data'].data.shape\n",
    "crop_h=crop_w=0\n",
    "transformer = caffe.io.Transformer({'data': (N,C,H+2*crop_h,W+2*crop_w)})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data', np.array([ 104,  117,  123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "\n",
    "def readImages(images):\n",
    "    imageLen=len(images)\n",
    "    imageDataList=[]\n",
    "    for imageIdx in range(imageLen):\n",
    "        imageName=images[imageIdx]\n",
    "        imageImage=transformer.preprocess('data', caffe.io.load_image(imageName))\n",
    "        imageDataList.append(imageImage[:,crop_h:H+crop_h,crop_w:W+crop_w]) #center crop\n",
    "        imageIdx+=1\n",
    "    #imageData and imageData\n",
    "    imageData=np.asarray(imageDataList)\n",
    "    return imageData\n",
    "\n",
    "def extract_features(file_list):\n",
    "    file_len=len(file_list)\n",
    "    features=[]\n",
    "    batch_size=300\n",
    "    for batch_idx in range(file_len/batch_size+1):\n",
    "        cur_len=batch_size if batch_idx <file_len/batch_size else file_len%batch_size\n",
    "        cur_list=file_list[batch_idx*batch_size+0:batch_idx*batch_size+cur_len]\n",
    "        image_data=readImages(cur_list)\n",
    "        net.blobs['data'].reshape(cur_len,C,H,W)\n",
    "        net.blobs['data'].data[:] = image_data\n",
    "        net.forward()\n",
    "        normed_features=net.blobs['normed_feature'].data.copy()\n",
    "        from sklearn.preprocessing import normalize\n",
    "        for idx in range(cur_len):\n",
    "            cur_feature=np.squeeze(normed_features[idx,:])\n",
    "#             cur_feature = cur_feature/np.linalg.norm(cur_feature)\n",
    "            features.append(cur_feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pid(name):\n",
    "    try: \n",
    "        pid=int(name[name.rfind('\\\\')+1:name.rfind('_')])\n",
    "    except:\n",
    "        pid=-1234\n",
    "    return pid\n",
    "\n",
    "def split_viper(data_dir,rand_seed=0):\n",
    "    import glob\n",
    "    #all images\n",
    "    cam_a_files=glob.glob(data_dir+'cam_a/*.bmp')\n",
    "    cam_b_files=glob.glob(data_dir+'cam_b/*.bmp')\n",
    "    all_dict={}\n",
    "    for a_file in cam_a_files:\n",
    "        person_id=get_pid(a_file)\n",
    "        all_dict[person_id]=[a_file]\n",
    "    for b_file in cam_b_files:\n",
    "        person_id=get_pid(b_file)\n",
    "        all_dict[person_id].append(b_file)\n",
    "    np.random.seed(rand_seed)\n",
    "    test_ids=np.random.choice(all_dict.keys(),len(all_dict)/2,replace=False)\n",
    "    #split\n",
    "    train_dict={}\n",
    "    test_dict={}\n",
    "    for person_id in all_dict:\n",
    "        if person_id in test_ids:\n",
    "            test_dict[person_id]=all_dict[person_id]\n",
    "        else:\n",
    "            train_dict[person_id]=all_dict[person_id]\n",
    "    return train_dict,test_dict\n",
    "\n",
    "def get_gt_dict(gallery_list):\n",
    "    gt_dict={}\n",
    "    for idx in range(len(gallery_list)):\n",
    "        gallery_name=gallery_list[idx]\n",
    "        gallery_person_id=int(gallery_name[gallery_name.rfind('\\\\')+1:gallery_name.rfind('_')])\n",
    "        if gt_dict.has_key(gallery_person_id):\n",
    "            gt_dict[gallery_person_id].append(idx)\n",
    "        else:\n",
    "            gt_dict[gallery_person_id]=[idx]\n",
    "    return gt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 316 316\n"
     ]
    }
   ],
   "source": [
    "#dataset related\n",
    "DATA_DIR=r'D:/v-limz/dataset/viper/VIPeR/'\n",
    "_,test_dict=split_viper(DATA_DIR)\n",
    "query_list=[]\n",
    "gallery_list=[]\n",
    "for pid in test_dict:\n",
    "    query_list.append(test_dict[pid][0])\n",
    "    gallery_list.append(test_dict[pid][1])\n",
    "gt_dict=get_gt_dict(gallery_list)\n",
    "print len(query_list),len(gallery_list),len(gt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 316\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic=time.time()\n",
    "query_features=extract_features(query_list)\n",
    "gallery_features=extract_features(gallery_list)\n",
    "toc=time.time()\n",
    "print len(query_features),len(gallery_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_for_queries(query_features,gallery_features):\n",
    "    import numpy as np\n",
    "    all_rank_list=[]\n",
    "    for query_idx in range(len(query_features)):\n",
    "        query_feature=query_features[query_idx]\n",
    "\n",
    "        score_list=[]\n",
    "        for gallery_idx in range(len(gallery_features)):\n",
    "            gallery_feature=gallery_features[gallery_idx]\n",
    "            dist = np.sqrt(np.sum((query_feature-gallery_feature)**2))\n",
    "            similar_score=1.0/(1.0+dist)\n",
    "            score_list.append(similar_score)\n",
    "        #we get scoreList, then cal predictLists\n",
    "        ranked_idx_list=np.argsort(score_list)[::-1]\n",
    "        all_rank_list.append(ranked_idx_list)\n",
    "    return all_rank_list\n",
    "\n",
    "######################################################\n",
    "##\n",
    "## I use parallel to run the query in batch_num=10 batches\n",
    "## In this way, one query on the 1w galleries takes 0.027s\n",
    "## Multi-process does not work for ipython notebook on Windows\n",
    "##\n",
    "######################################################\n",
    "def parallel_rank(query_features,gallery_features):\n",
    "    import ipyparallel as ipp\n",
    "    client = ipp.Client()\n",
    "    view = client.load_balanced_view()\n",
    "    batch_num=2*len(client.ids)\n",
    "    batch_size_queries=len(query_features)/batch_num+1\n",
    "\n",
    "    tic=time.time()\n",
    "    task_results=[]\n",
    "    for task_idx in range(batch_num):\n",
    "        batch_query_features=query_features[task_idx*batch_size_queries:(task_idx+1)*batch_size_queries]\n",
    "        task_results.append(view.apply(rank_for_queries,batch_query_features,gallery_features))    \n",
    "\n",
    "    all_rank_list=[]\n",
    "    for task_idx in range(batch_num):\n",
    "        all_rank_list.extend(task_results[task_idx].result())\n",
    "    toc=time.time()\n",
    "    print len(all_rank_list),(toc-tic),(toc-tic)/len(query_list)\n",
    "    return all_rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 0.599999904633 0.00189873387542\n"
     ]
    }
   ],
   "source": [
    "# all_rank_list=rank_for_queries(query_features,gallery_features)\n",
    "all_rank_list=parallel_rank(query_features,gallery_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40506329  0.50949367  0.57278481  0.61708861  0.64556962  0.67088608\n",
      "  0.69620253  0.71202532  0.7278481   0.74683544  0.75949367  0.76582278\n",
      "  0.78164557  0.78481013  0.79113924  0.80696203  0.81329114  0.81962025\n",
      "  0.83227848  0.83227848  0.84177215  0.84493671  0.85126582  0.86075949\n",
      "  0.86392405  0.86392405  0.87974684  0.87974684  0.88291139  0.88924051\n",
      "  0.89556962  0.89873418  0.90189873  0.90506329  0.90506329  0.91139241\n",
      "  0.91772152  0.92088608  0.92088608  0.92405063  0.92721519  0.92721519\n",
      "  0.93037975  0.93670886  0.93670886  0.93670886  0.93670886  0.93987342\n",
      "  0.94620253  0.94620253] 0.51900619095\n"
     ]
    }
   ],
   "source": [
    "histogram=np.zeros(len(gallery_list))\n",
    "meanAP=0.0\n",
    "len_queries=len(query_list)\n",
    "for query_idx in range(len_queries):#\n",
    "    ranked_idx_list=all_rank_list[query_idx]\n",
    "    #good or junk\n",
    "    query_name=query_list[query_idx]\n",
    "    query_person_id=get_pid(query_name)\n",
    "    relevant_idx_list=gt_dict[query_person_id]\n",
    "    #cmc and meanAP\n",
    "    matched_num=0.0\n",
    "    sum_precision=0.0\n",
    "    rank_idx=0\n",
    "    for perdicted_idx in ranked_idx_list:\n",
    "        if perdicted_idx in relevant_idx_list:\n",
    "            matched_num+=1.0\n",
    "            sum_precision+=matched_num/(rank_idx+1)\n",
    "            histogram[rank_idx]+= 1 if matched_num<=1 else 0 #multiple results\n",
    "        rank_idx+=1\n",
    "        if matched_num>=len(relevant_idx_list): #recall=1\n",
    "            break\n",
    "    meanAP+=sum_precision/len(relevant_idx_list)\n",
    "        \n",
    "cmc=np.cumsum(histogram)/len_queries\n",
    "meanAP/=len_queries\n",
    "print cmc[:50],meanAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./viper_origin_with_cuhk/model_iter_6000,160x80: 0.408227848101 0.538970073989\n"
     ]
    }
   ],
   "source": [
    "print EXP_DIR+model_name+\",\"+\"%dx%d\"%(H,W)+\":\",cmc[0],meanAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
